{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Assessment Exercise for ASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-05-11 15:02:35--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘train-images-idx3-ubyte.gz’\n",
      "\n",
      "100%[======================================>] 9,912,422   2.96MB/s   in 3.2s   \n",
      "\n",
      "2017-05-11 15:02:38 (2.96 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
      "\n",
      "--2017-05-11 15:02:38--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
      "\n",
      "100%[======================================>] 28,881      --.-K/s   in 0.1s    \n",
      "\n",
      "2017-05-11 15:02:39 (263 KB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2017-05-11 15:02:39--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/x-gzip]\n",
      "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
      "\n",
      "100%[======================================>] 1,648,877   1.30MB/s   in 1.2s   \n",
      "\n",
      "2017-05-11 15:02:40 (1.30 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
      "\n",
      "--2017-05-11 15:02:40--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/x-gzip]\n",
      "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
      "\n",
      "100%[======================================>] 4,542       --.-K/s   in 0s      \n",
      "\n",
      "2017-05-11 15:02:41 (83.5 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
      "\n",
      "--2017-05-11 15:02:41--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 170498071 (163M) [application/x-gzip]\n",
      "Saving to: ‘cifar-10-python.tar.gz’\n",
      "\n",
      "100%[======================================>] 170,498,071 2.41MB/s   in 1m 47s \n",
      "\n",
      "2017-05-11 15:04:29 (1.51 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Download data\n",
    "# MNIST\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "# CIFAR\n",
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: train-labels-idx1-ubyte.gz: No such file or directory\n",
      "gzip: t10k-images-idx3-ubyte.gz: No such file or directory\n",
      "gzip: t10k-labels-idx1-ubyte.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!gzip -d train-images-idx3-ubyte.gz\n",
    "!gzip -d train-labels-idx1-ubyte.gz\n",
    "!gzip -d t10k-images-idx3-ubyte.gz\n",
    "!gzip -d t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "!tar -xf cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training data size: ', 60000)\n",
      "('Test data size', 10000)\n",
      "('Image size: ', (784,))\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "# load data to note book\n",
    "def read_mnist_data(images_file_name, labels_file_name):\n",
    "#     images_file_name = \"train-images-idx3-ubyte\"\n",
    "#     labels_file_name = \"train-labels-idx1-ubyte\"\n",
    "    dataset = []\n",
    "    with open(images_file_name, 'rb') as foi:\n",
    "        with open(labels_file_name, 'rb') as fol:\n",
    "            foi.read(4), fol.read(8) # omit magic number\n",
    "            n_image = struct.unpack(\">i\", foi.read(4))[0]\n",
    "            n_row = struct.unpack(\">i\", foi.read(4))[0]\n",
    "            n_col = struct.unpack(\">i\", foi.read(4))[0]\n",
    "            for i in np.arange(n_image):\n",
    "                dataset.append((struct.unpack(\">B\", fol.read(1))[0],\n",
    "                                np.array(struct.unpack(\">\" + \"B\"*(n_row*n_col), foi.read(n_row*n_col)))))\n",
    "    return dataset\n",
    "#             dataset.append()\n",
    "#     print(magic, n_image, n_row, n_col)\n",
    "mnist_training_data = read_mnist_data(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\")\n",
    "mnist_test_data = read_mnist_data(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\")\n",
    "print(\"Training data size: \", len(mnist_training_data))\n",
    "print(\"Test data size\", len(mnist_test_data))\n",
    "print(\"Image size: \", mnist_training_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(3, array([235, 231, 232, ..., 178, 191, 199], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "# read CIFAR10\n",
    "CIFAR_FOLDER = \"./cifar-10-batches-py\"\n",
    "data_batch_file = [\"data_batch_1\", \"data_batch_2\", \"data_batch_3\", \"data_batch_4\", \"data_batch_5\"]\n",
    "test_batch_file = \"test_batch\"\n",
    "\n",
    "def unpickle(filename):\n",
    "    import cPickle as pkl\n",
    "    with open(filename, 'rb') as fo:\n",
    "        dictionary = pkl.load(fo)\n",
    "    result = [(dictionary[\"labels\"][i], np.array(dictionary[\"data\"][1]))\n",
    "                     for i in np.arange(len(dictionary[\"data\"]))]\n",
    "    return result\n",
    "\n",
    "cifar_full_data = []\n",
    "for filename in data_batch_file:\n",
    "    cifar_full_data.append(unpickle(CIFAR_FOLDER + \"/\" + filename))\n",
    "\n",
    "    \n",
    "cifar_test_data = unpickle(CIFAR_FOLDER + \"/\" + test_batch_file)\n",
    "print(len(cifar_full_data))\n",
    "print(cifar_test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3/ 1. Naive Bayes\n",
    "import scipy\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, n_class, n_feature, feature_value_range):\n",
    "        self.n_class = n_class\n",
    "        self.n_feature = n_feature\n",
    "        self.feature_value_range = feature_value_range\n",
    "        self.probability_matrix = np.ones((n_class, n_feature, feature_value_range)) * 1.0\n",
    "        self.probability_class = np.zeros((n_class)) * 1.0\n",
    "        \n",
    "    def train(self, training_data, training_label):\n",
    "        # label already int from (0,.., n_class - 1)\n",
    "        # training data (n_data x n_feature)\n",
    "        for i in np.arange(len(training_data)):\n",
    "            self.probability_class[training_label[i]] += 1.0\n",
    "            for j in np.arange(len(training_data[0])):\n",
    "                self.probability_matrix[training_label[i], j, training_data[i][j]] += 1.0\n",
    "        self.probability_matrix = self.probability_matrix / np.sum(self.probability_matrix, axis=2).reshape((self.n_class, self.n_feature, 1))\n",
    "        self.probability_class = self.probability_class / len(training_data)\n",
    "        return self.probability_matrix\n",
    "    \n",
    "    def predict_one(self, test_data):\n",
    "        result = 1.0\n",
    "        for i in np.arange(len(test_data)):\n",
    "            result = result * self.probability_matrix[:, i, test_data[i]]\n",
    "        result = result * self.probability_class\n",
    "#         print np.argmin(result)\n",
    "        return (np.argmax(result), result)\n",
    "    \n",
    "    def predict_all(self, test_datas):\n",
    "        result_array = np.zeros((len(test_datas), self.n_class))\n",
    "        result_idx = np.zeros((len(test_datas),1))\n",
    "        for i in np.arange(len(test_datas)):\n",
    "            class_idx, prob_array = self.predict_one(test_datas[i])\n",
    "            result_array[i, :] = prob_array\n",
    "            result_idx[i] = class_idx\n",
    "        return (result_idx, result_array)\n",
    "    \n",
    "    def predict_score(self, test_datas, test_labels):\n",
    "        result_idx, _ = self.predict_all(test_datas)\n",
    "        return np.sum([result_idx[i] == test_labels[i] for i in np.arange(len(test_datas))]) / float(len(test_datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parallels/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/parallels/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8413\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "classifier = NaiveBayesClassifier(10, 28*28, 2)\n",
    "classifier.train([1.0*(x[1]>0) for x in mnist_training_data], [x[0] for x in mnist_training_data]);\n",
    "print(classifier.predict_score([1.0*(x[1]>0) for x in mnist_test_data], [x[0] for x in mnist_test_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "nb = MultinomialNB()\n",
    "y_pred = (nb.fit([x[1] for x in mnist_training_data], [x[0] for x in mnist_training_data])\n",
    "          .predict([x[1] for x in mnist_test_data]))\n",
    "print(np.sum(y_pred == [x[0] for x in mnist_test_data]) * 1.0 / len(mnist_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
